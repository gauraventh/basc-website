"use strict";(self.webpackChunkbasc_website=self.webpackChunkbasc_website||[]).push([[54],{6034:(e,t,a)=>{a.r(t),a.d(t,{default:()=>h});var n=a(7294),i=a(6010),r=a(9960),s=a(7961);const o=a.p+"assets/images/interp-32e77718e4410b5e8edc2ddd17260f78.png",l=a.p+"assets/images/policy-e3d8d26ceaaf5919f09ebda5d426e600.png",c={heroBanner:"heroBanner_qdFl",gradientBackground:"gradientBackground_aReF",heroBody:"heroBody_fd5Q",heroButtons:"heroButtons_r52D",section:"section_Q9Zo",sectionContainer:"sectionContainer_WLPJ",textHalf:"textHalf_Xzed",imageHalf:"imageHalf_GtVh",interp:"interp_Q2p8",interpContainer:"interpContainer_UzIG",policy:"policy_robi",policyContainer:"policyContainer_taSD"};function m(){return n.createElement("div",{className:(0,i.Z)("hero hero--primary",c.heroBanner)},n.createElement("div",{className:"container"},n.createElement("h1",{className:"hero__title"},"Bristol AI Safety Centre (BASC)"),n.createElement("p",{className:(0,i.Z)("hero__subtitle",c.heroBody)},"We are BASC, a research organization dedicated to preventing existential risks and steering the future of AGI towards positive outcomes for humanity. We focus on interpretability and AI policy research."),n.createElement("div",{className:c.heroButtons},n.createElement(r.Z,{className:"button button--secondary button--lg",to:"/about"},"Read more about us"))))}function d(){return n.createElement("div",{className:(0,i.Z)(c.section,c.interp)},n.createElement("div",{className:(0,i.Z)("container",c.sectionContainer,c.interpContainer)},n.createElement("div",{className:c.textHalf},n.createElement("h2",null,"Interpretability research"),n.createElement("p",null,'Modern AI systems are "black boxes" \u2014 it\'s impossible to understand why they make the decisions they do. This is makes it difficult to evaluate safety properties of these systems, which in turn makes it difficult to design effective regulations around them. We are working on changing that.')),n.createElement("div",{className:c.imageHalf},n.createElement("img",{src:o,alt:"Interpretability"}))))}function u(){return n.createElement("div",{className:(0,i.Z)(c.section,c.policy)},n.createElement("div",{className:(0,i.Z)("container",c.sectionContainer,c.policyContainer)},n.createElement("div",{className:c.imageHalf},n.createElement("img",{src:l,alt:"AI Policy"})),n.createElement("div",{className:c.textHalf},n.createElement("h2",null,"AI policy research"),n.createElement("p",null,"There is still plenty of low-hanging fruit in the realm of AI policy. What does effective regulation aimed at reducing existential risks from AGI even look like? Our policy research aims to shed light at this question."))))}function h(){return n.createElement(s.Z,{description:"BASC is a small research group working on AGI safety, interpretability, and policy."},n.createElement("main",null,n.createElement(m,null),n.createElement(d,null),n.createElement(u,null)))}}}]);